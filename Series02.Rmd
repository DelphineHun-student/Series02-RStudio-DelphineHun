---
title: "Series-02-Rstudio : Data mining and statistical tests"
author: "Delphine HUND"
date: "`r format(Sys.time(), '%d %B, %Y, %H:%M')`"
output:
  html_document:
    df_print: paged
    code_folding: hide
    toc: false
    number_sections: true
---
# Correlations and linear regression

In this series, the aim is to explore correlations and linear regression, using a dataset from a real experiment.

### The problem

We investigate whether there is a relationship between the nonuse of the proximal part of the upper limb (PANU) and the nonuse of the shoulder (SANU) or the elbow (EENU).

## Methods

### Dataset

The dataset is far from perfect, which reflects the reality of experimental research, particularly in clinical contexts.

```{r load data}
nonuse <- read.csv("data/test_data/NonUse.csv", sep=",", header=TRUE)
head(nonuse)
summary(nonuse)
```
### Variables
This file contains measures of upper extremity nonuse:

    PANU: Proximal Arm Non Use
    SANU: Shoulder Antepulsion Non Use
    EENU: Elbow Extension Non Use


Description of the experiment, the variables and the data (units and the range of possible values).

| name | description | unit | range |
|:----:|:-----------:|:----:|:-----:|
| PANU | Proximal Arm Non Use | % | O-100 |
| SANU | Shoulder Antepulsion Non Use | % | O-100 |
| EENU | Elbow Extension Non Use | % | O-100 |

## Analyses

### Corelation analysis

- Correlation between PANU/SANU

We used a Spearman correlation, because we don't have assumptions about the distribution of the data. We do not assume linear relationship between variables.
```{r correlation PANU-SANU}
cor.test(nonuse$PANU, nonuse$SANU, method = "spearman")
```
- Correlation between PANU/EENU
```{r correlation PANU-EENU}
cor.test(nonuse$PANU, nonuse$EENU, method = "spearman")
```

### Relationship with PANU

- PANU-SANU relationship

```{r plot SANU-lm}
library(ggplot2)
ggplot(nonuse, aes(x=PANU, y=SANU)) +
  geom_point() +
  geom_smooth(method='lm', formula= y~x, color='blue', se=T) +
  # xlim(-10, 60) +
  # ylim(-50, 50) +
  
labs(title="PANU vs. SANU", x="PANU (%)", y="SANU (%)")
```

- PANU-EENU relationship

```{r plot EENU-lm}

ggplot(nonuse, aes(x=PANU, y=EENU)) +
  geom_point() +
  geom_smooth(method='lm', formula= y~x, color='blue', se=T) +
  # xlim(-10, 60) +
  # ylim(-50, 50) +
  
labs(title="PANU vs. EENU", x="PANU (%)", y="EENU (%)")
```

### Linear regression

- PANU-SANU

```{r lm/SANU}
lm_sanu <- lm(SANU ~ PANU, data=nonuse)
summary(lm_sanu)
coef(lm_sanu)
slope_1 <- coef(lm_sanu)[2]
intercept_1 <- coef(lm_sanu)[1] #?
cat("Regression equation: SANU=", slope_1, "PANU +", intercept_1, "\n")
```

- PANU-EENU

```{r lm/EENU}
lm_eenu <- lm(EENU ~ PANU, data=nonuse)
summary(lm_eenu)
coef(lm_eenu)
slope_2 <- coef(lm_eenu)[2]
intercept_2 <- coef(lm_eenu)[1] 
cat("Regression equation: EENU=", slope_2, "PANU +", intercept_2, "\n")
```
## Regression equations
(PANU = a * SANU + b and PANU = a * EENU + b)

```{r equations PANU}
a <- 1 / slope_1
b <- -intercept_1 / slope_1

cat("Regression equation : PANU =", a, "* SANU +", b, "\n")

# PANU = a*EENU + b
a <- 1 / slope_2
b <- -intercept_2 / slope_2

cat("Regression equation : PANU =", a, "* EENU +", b, "\n")
```

## Results

Spearman’s rank correlation rho showed a weak but significant positive association between PANU and SANU (ρ = 0.216, p = 0.0017), while a moderate and significant positive association was found between PANU and EENU (ρ = 0.387, p < 0.0001). Linear regression analyses confirmed these results: no significant relationship was observed between SANU and PANU (SANU = 0.089 × PANU + 0.586, R² = 0.009, p = 0.171), whereas a significant positive relationship was found between EENU and PANU (EENU = 0.565 × PANU + 3.284, R² = 0.225, p < 0.0001). When PANU was expressed as a function of SANU and EENU, the regression equations obtained were PANU = 11.195 × SANU – 6.561 and PANU = 1.771 × EENU – 5.816,  respectively.
(with GPT's help)

## Limits

The present analysis has several limitations.
First, the correlations observed were relatively weak, with rho values of 0.216 for PANU–SANU and 0.387 for PANU–EENU, indicating that only a small proportion of the variance is explained.
Second, the linear regression between PANU and SANU was not significant (R² = 0.009, p = 0.171), and even the significant regression between PANU and EENU explained only a modest proportion of variance (R² = 0.225).
Third, the dataset contains a high number of missing values (223 for SANU and EENU, 13 for PANU), reducing statistical power and potentially biasing the analysis.
In addition, the variables show large variability and extreme values, which may reflect outliers or measurement noise.
Finally, the use of linear regression assumes a linear relationship, which may not fully capture the complexity of the data
(with GPT's help)

# Statistical tests: comparison of medians/means

In this series of exercises, the aim is to explore how to compare two groups of data, using non-parametric tests (or parametric tests).

## Definition

### Mean and median
The mean is the arithmetic average of a dataset. Median is the middle value that divides the dataset into two equal halves

- https://www.khanacademy.org/math/statistics-probability/summarizing-quantitative-data

### Variance and Standard Deviation (SD)
Variance measures the average squared distance from the mean, while the standard deviation is its square root, expressed in the same units as the data.

- https://www.statisticshowto.com/probability-and-statistics/statistics-definitions/variance/

### A normal distribution

A normal distribution is a symmetric, bell-shaped curve characterized by its mean and standard deviation.

- https://www.khanacademy.org/math/statistics-probability/modeling-distributions-of-data

### Statistical test
A statistical test is a method to decide if data provide enough evidence to reject a null hypothesis

- https://en.wikipedia.org/wiki/Statistical_hypothesis_testing

### When to use a statistical test?
A statistical test is used when we need to evaluate if an observed effect is unlikely to have occurred by chance.

- https://www.scribbr.com/statistics/statistical-tests

### Parametric test and non-parametric test
Parametric tests assume specific data distributions (e.g., normality), while non-parametric tests make fewer assumptions and work with ranks or ordinal data.

- https://www.scribbr.com/statistics/statistical-tests

### Assumptions of parametric tests
Parametric tests typically assume that the data (or residuals) are normally distributed, that variances are homogeneous across groups, that observations are independent, and that the variables are measured on an interval or ratio scale.

- https://www.scribbr.com/frequently-asked-questions/assumptions-of-statistical-tests/

### Assumptions of non-parametric tests
Non-parametric tests assume fewer conditions, mainly independence of observations and appropriate data scale (ordinal or rank).

- https://www.scribbr.com/statistics/nonparametric-tests/

### p-value
A p-value is the probability of observing results as extreme as those in your sample, assuming the null hypothesis is true.

- https://www.scribbr.com/statistics/p-value/

### What is the risk of error when using a statistical test?
A test involves risks: rejecting H0 when it is true (Type I error, α) or failing to reject H0 when H1 is true (Type II error, β).

- https://www.scribbr.com/statistics/type-i-and-type-ii-errors/

### What is the difference between a paired and an unpaired test?
A paired test compares related samples (e.g., before/after on the same subjects), while an unpaired test compares independent groups.

- https://www.scribbr.com/statistics/paired-t-test-vs-unpaired-t-test/

## Effect of treatment over time
In clinical and sport research, a common question is whether a treatment or training intervention produces an effect over time. To address this scientifically, measurements need to be collected before and after the intervention, and ideally at later time points, to evaluate both the immediate and the lasting effects

### The data
```{r load data PrePost}
prepost <- read.csv("data/test_data/PrePost.csv", sep=",", header=TRUE)
head(prepost)
summary(prepost)
```


This file contains before/after measurements. The treatment is a rehabilitation training for individuals with cardiac conditions.

| Variable | Description         | Unit   | Possible values             | Expected change           |
|:---------|:-------------------:|:------:|:---------------------------:|:-------------------------:|
| perf     | Performance Measure | bpm    | Numeric values (50–200)     | increase after rehab      |
| time     | Time of measurement | factor | "Before" / "After"          | no change                 |

| Variable | Description | Unit | Possible values | Expected change |

### The analysis

**Aim?**
We want to test whether the treatment leads to a measurable improvement in performance. Based on the design of the study, we expect the treatment to have a positive effect.

**Comparison?**
We will compare the performance of the same participants before and after the treatment. Since the same subjects are measured twice, this is a paired comparison.

**Test?**
Before choosing the appropriate statistical test, we first need to assess whether the differences between before and after measurements follow a normal distribution. Given the small sample size, the Shapiro–Wilk test was considered the most appropriate method to assess the normality of the distribution of differences

- https://statistics.laerd.com/spss-tutorials/testing-for-normality-using-spss-statistics.php
```{r Shapiro-Wilk test}
before = prepost$perf[prepost$time=="Before"]
after = prepost$perf[prepost$time=="After"]

diff <- after - before
shapiro.test(diff)
```
The Shapiro–Wilk test indicated that the distribution of the differences did not significantly deviate from normality (W = 0.899, p = 0.283). Therefore, we applied a paired t-test to evaluate the effect of the treatment

```{r t test efect of treatment} 
resultat <- t.test(before, after, paired = TRUE)

resultat
```

**Graph?**

```{r plot effect of treatment}
df_plot <- data.frame(
  value = c(before, after),
  time  = factor(rep(c("Before", "After"), each = length(before)),
                 levels = c("Before", "After"))
)

library(ggplot2)
ggplot(df_plot, aes(x = time, y = value, fill = time)) +
  geom_boxplot(alpha = 0.4) +
  geom_jitter(width = 0.1, size = 2) +
  labs(title = "Effect of treatment",
       x = "Time", y = "Performance") +
  theme_minimal()
```

**Results?** A paired t-test revealed that performance was significantly higher after the treatment compared to before (t(7) = –5.40, p = 0.001). The mean improvement was 2.5 units, with a 95% confidence interval ranging from 1.41 to 3.59, indicating a positive effect of the rehabilitation program.


## Testing some stereotypes
Stereotypes about snorers among others.

### The data
```{r load data snore}
data_s <- read.table("data/test_data/snore.txt", header = TRUE)
head(data_s)
summary(data_s)
```
This file contains anthropometric and qualitative measurements (1 person per line).

### The analysis
Do the data confirm the following stereotypes? Provide a reasoned answer (data, figure, result sentence) for each question.

#### Are snorers fatter?
```{r}
weight = data_s$weight
shapiro.test(weight)
```
The Shapiro–Wilk test indicated that the distribution significantly deviate from normality (W = 0.899, p < 0.001).

```{r plot + wilcoxon test}
boxplot(weight ~ snore, data = data_s,
        main = "Weight by Snorer Status",
        xlab = "Snorer", ylab = "Weight")

wilcox.test(weight ~ snore, data = data_s)
```
**Results :** There was no significant difference in weight between snorers and non-snorers (p = 0.9079), suggesting that the stereotype is not confirmed in this sample

#### Do snorers drink more? Smoke more?

**Alcool consumption :**
```{r}
alcool = data_s$alcool
shapiro.test(alcool)
```
The Shapiro–Wilk test indicated that the distribution significantly deviate from normality (W = 0.83114, p < 0.001)

```{r plot + wilcoxon test alcool}
boxplot(alcool ~ snore, data = data_s,
        main = "Alcool consumption by Snorer Status",
        xlab = "Snorer", ylab = "Weight")

wilcox.test(alcool ~ snore, data = data_s)
```
**Results :** There is a significant difference in alcool consomation between snorers and non-snorers (p =  0.008594), suggesting that the stereotype is confirmed in this sample/

**Tabac consumption**
```{r Chi-square test smoke/snore}
tab_1 <- table(data_s$snore, data_s$tabac)
tab_1

# Chi-square test
chisq.test(tab_1)

```
```{r}
prop_tab_1 <- prop.table(tab_1, margin = 1)  # proportion par ligne
barplot(t(prop_tab_1), beside = TRUE, legend = TRUE,
        main = "Smoking status by Snorer Status",
        xlab = "Snorer Status", ylab = "Proportion")
```

**Results :** No significant difference was found in smoking prevalence between snorers and non snorers (p = 0.4066), suggesting that the stereotype is not confirmed by the data.

#### Are men fatter?
```{r shapiro test H/F}
men = data_s$weight[data_s$sex=="H"]
women = data_s$weight[data_s$sex=="F"]

diff_HF = women - men
shapiro.test(diff_HF)
```
The Shapiro–Wilk test indicated that the distribution of the differences did not significantly deviate from normality (W = 0.97383, p = 0.1223). Therefore, we applied a paired t-test to evaluate the imapact of the sex on weight.

```{r t test efect of sex} 
resultat <- t.test(women, men, paired = FALSE)
resultat
```

```{r plot effect of sex on weight}
w_plot <- data.frame(
  value = c(women, men),
  time  = factor(rep(c("Women", "Men"), each = length(women)),
                 levels = c("Women", "Men"))
)

library(ggplot2)
ggplot(w_plot, aes(x = time, y = value, fill = time)) +
  geom_boxplot(alpha = 0.4) +
  geom_jitter(width = 0.1, size = 2) +
  labs(title = "Effect of sex on weight",
       x = "Sex", y = "Weight") +
  theme_minimal()
```

**Results :** There was no significant difference in weight between men and women (p = 0.7331). Stereotype.

#### Do women smoke less?
```{r Chi-square test}
tab <- table(data_s$sex, data_s$tabac)
tab

# Chi-square test
chisq.test(tab)

```
```{r}
prop_tab <- prop.table(tab, margin = 1)  # proportion par ligne
barplot(t(prop_tab), beside = TRUE, legend = TRUE,
        main = "Smoking status by sex",
        xlab = "Sex", ylab = "Proportion")
```

**Results : ** A chi-square test revealed that women were significantly less likely to smoke than men (χ² = 7.0023, p = 0.00814), supporting the stereotype that women smoke less.


#### Are there any correlations between variables?

```{r correlations between variables}
cor.test(data_s$age, data_s$weight, method = "spearman")
cor.test(data_s$age, data_s$height, method = "spearman")
cor.test(data_s$weight, data_s$height, method = "spearman")
```
- Spearman’s rank correlations did not reveal any significant associations between age, weigh consumption (all p > 0.05). Spearman’s rank correlation rho only showed a significant positive association between weight and height.